---
title: "HOMEWORK 1 - Creating Value Through Data Mining (S402010)"
author: "Liam Phan"
date: "`r Sys.Date()`"
output:
  rmdformats::material :
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: tango
---
# Quick Start

> Most of the plots are interactive, you can click or zoom to get more details ! Also don't hesitate to click on plots, they will zoom automatically ! 

## Loading Packages

```{r 2, warning=FALSE, message=FALSE }

# Loading Packages 

library(data.table)
library(lubridate)
library(tidyverse)
library(esquisse)
library(plyr)
library(ggplot2)
library(cowplot)
library(naniar) #for NA exploration
library(sp) #spatial data
library(reshape2)
library(plotly)
library(gissr)
library(leaflet)
library(leaflet.providers)
library(geosphere)
library(DT)

```

> Those are required packages


# Ex 3.4
## Loading Datas and Cleaning

> Loading the dataset called "LaptopSales_red.csv" given for the Homework

```{r 3,echo=FALSE, warning=FALSE, comment=FALSE}

Laptop_Sales_Data <- fread("DATA/LaptopSales_red.csv")

#is.data.table(Laptop_Sales_Data)

#summary(Laptop_Sales_Data)

str(Laptop_Sales_Data)

```

<center>

```{r 333, echo=FALSE, warning=FALSE, comment=FALSE}

gg_miss_var(Laptop_Sales_Data, show_pct = TRUE)

```


> Retail Price is the only variable missing at rate of approximately 4% 

</center>

## a.Price Questions:

```{r 4, include=FALSE}

#### Set Up a Data Subset and NA OMIT

Retail_Price_and_Dates <- Laptop_Sales_Data[,.(Retail.Price,Date)][,Date:=mdy_hm(Date)]

Retail_Price_and_Dates <- na.omit(Retail_Price_and_Dates)

```


### i. At What Price are the laptops actually selling ?

<center>

```{r 5, echo=FALSE}

# Histogram of the Retail Price of Computer In 2018
ggplotly(
ggplot(Retail_Price_and_Dates) +
 aes(x = Retail.Price) +
 geom_histogram(bins = 30L, fill = "#1c6155") +
 labs(x = "Price", y = "Frequency", title = "Histogram of the Retail Price of Computer", subtitle = "In 2018") + theme_classic()
)

```

> This barplot shows the most frequent retail prices for all stores in 2018

</center>

```{r 51, echo=FALSE, warning=FALSE, comment=FALSE}

# Boxplot of the Retail Price of Computer In 2018

ggplotly(
ggplot(Retail_Price_and_Dates) +
 aes(x = "", y = Retail.Price) +
 geom_boxplot(fill = "#1c6155") + stat_summary(fun.y=mean, geom="point", shape=20, size=8, color="white", fill="white") + 
 labs(y = "Price", x="",
 title = "Boxplot of the Retail Price of Computer", subtitle = "In 2018") +
 theme_classic()
)

```

</center>

> We can interpret this boxplot as the mean or median retail price of the 2018 Computer Dataset, click on the white sphere to get the mean !

```{r 52, include=FALSE}

# Actual price

Max_Date_Retail <- max(Retail_Price_and_Dates$Date)

Actual_Price <- Retail_Price_and_Dates[Date %in% Max_Date_Retail, ]

```

```{r 53,echo=FALSE}

result1 <- print(paste("Last Recorded Prices are", Actual_Price[1,1], "USD", "and", Actual_Price[2,1],"USD","on the same Day with a mean of",mean(Actual_Price$Retail.Price),"USD"))

```

> Here is given the last recorded prices for 2018


### ii.Does price change with time?


```{r 61, include=FALSE}

# Aggregating by Month
Retail_Price_and_Dates_Month <- Retail_Price_and_Dates[, mean(Retail.Price), by = floor_date(Date,unit="month")]

colnames(Retail_Price_and_Dates_Month)[1] <- "Date"
colnames(Retail_Price_and_Dates_Month)[2] <- "Mean_Retail_Price"

# Aggregating by Week
Retail_Price_and_Dates_Week <- Retail_Price_and_Dates[, mean(Retail.Price), by = floor_date(Date,unit = "week")]

colnames(Retail_Price_and_Dates_Week)[1] <- "Date"
colnames(Retail_Price_and_Dates_Week)[2] <- "Mean_Retail_Price"

# Aggregating by Day
Retail_Price_and_Dates_Day <- Retail_Price_and_Dates[, mean(Retail.Price), by = floor_date(Date,unit = "day")]

colnames(Retail_Price_and_Dates_Day)[1] <- "Date"
colnames(Retail_Price_and_Dates_Day)[2] <- "Mean_Retail_Price"

# Aggregating by Weekday

Retail_Price_and_Dates_WeekDay <- Retail_Price_and_Dates[,Weekday:=weekdays(Date)]
Retail_Price_and_Dates_WeekDay <- Retail_Price_and_Dates_WeekDay[,mean(Retail.Price),by=Weekday]

Retail_Price_and_Dates_WeekDay <- Retail_Price_and_Dates_WeekDay %>% mutate(Translation=c("Saturday","Friday","Wednesday","Monday","Tuesday","Thursday","Sunday"))

Retail_Price_and_Dates_WeekDay$Translation <- factor(Retail_Price_and_Dates_WeekDay$Translation, ordered = TRUE, levels=(c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")))

colnames(Retail_Price_and_Dates_WeekDay)[2] <- "Mean_Retail_Price"

```

<center>

```{r 6, echo=FALSE}

# Retail Price By Month
RetailPricePlot1 <- ggplotly(
  ggplot(Retail_Price_and_Dates_Month) +
 aes(x = Date, y = Mean_Retail_Price) +
 geom_line(size = 1.1, 
 colour = "#1c6155") + geom_point() +
 labs(x = "Months", y = "Average Retail Pric", title = "Average Retail Price of Computer in 2018", 
 subtitle = "Aggregated by Month") +
 theme_classic()
 )

RetailPricePlot1

# Retail Price By Week
RetailPricePlot2 <- ggplotly(
  ggplot(Retail_Price_and_Dates_Week) +
 aes(x = Date, y = Mean_Retail_Price) +
 geom_line(size = 0.4, 
 colour = "#1c6155") + geom_point() +
 labs(x = "Weeks", y = "Average Retail Pric", title = "Average Retail Price of Computer in 2018", 
 subtitle = "Aggregated by Week") +
 theme_classic()
 )

RetailPricePlot2

# Retail Price By Day
RetailPricePlot3 <- ggplotly(
  ggplot(Retail_Price_and_Dates_Day) +
 aes(x = Date, y = Mean_Retail_Price) +
 geom_line(size = 0.2, 
 colour = "#1c6155")  +
 labs(x = "Days", y = "Average Retail Price", title = "Average Retail Price of Computer in 2018", 
 subtitle = "Aggregated by Day") + 
 theme_classic()
 )

RetailPricePlot3

# Retail Price By Week Day

RetailPricePlot4 <- ggplotly(
  ggplot(Retail_Price_and_Dates_WeekDay) +
 aes(x = Translation, y = Mean_Retail_Price) +
 geom_col(fill = "#1c6155") +
 labs(x = "Weekdays", y = "Average Retail Price", title = "Average Retail Price during Weekdays", subtitle = "In 2018") + 
 theme_classic() + coord_cartesian(ylim = c(505, 510))
)

RetailPricePlot4

```

</center>

> Those Plot shows different aggregations levels, can be used depending on the analysis we want, thus the granularity need.

### iii. Are prices consistent across retail outlets?


```{r 7, include=FALSE}

#### Set Up a Data Subset and NA OMIT

Retail_Price_Outlets_Date <- Laptop_Sales_Data[,.(Retail.Price,Store.Postcode,Date)][,Date:=mdy_hm(Date)]

Retail_Price_Outlets_Date  <- na.omit(Retail_Price_Outlets_Date)

Retail_Price_Configuration <- Laptop_Sales_Data[,.(Retail.Price,Configuration,Screen.Size..Inches.,Battery.Life..Hours.,RAM..GB.,Processor.Speeds..GHz.,Integrated.Wireless.,HD.Size..GB.,Bundled.Applications.)]

Retail_Price_Configuration <- na.omit(Retail_Price_Configuration)

```


<center>

```{r 8,echo=FALSE}

#### Boxplot Across Retail Outlets

ggplotly(
ggplot(Retail_Price_Outlets_Date) +
 aes(x = Store.Postcode, y = Retail.Price) +
 geom_boxplot(fill = "#1c6155") +
 labs(x = "Stores Postcode", y = "Price", title = "Boxplot Of The Retail Price Across Stores", subtitle = "In 2018") +
 theme_classic() + scale_x_discrete(guide = guide_axis(n.dodge = 1)) + theme(axis.text.x=element_text(size=rel(1), angle=90))
)

```

</center>

> Each box plots belongs to a specific stores, we can see a common trend across all stores in 2018


```{r 81, include=FALSE}

#### Retail Price Across Stores During 2018 - Data

Retail_Price_Outlets_Date_Month <- Retail_Price_Outlets_Date[,Floor.Date:=floor_date(Date,unit="month")][,c(Mean_Price=mean(Retail.Price)), by=list(Store.Postcode,Floor.Date)]

colnames(Retail_Price_Outlets_Date_Month)[3] <- "Mean_Retail_Price"

```

<center>


```{r 83, echo=FALSE}

#### Plot of the Monthly Retail Price per Stores
ggplotly(
ggplot(Retail_Price_Outlets_Date_Month) +
 aes(x = Floor.Date, y = Mean_Retail_Price, colour = Store.Postcode) +
 geom_line(size = 0.5) +
 scale_color_hue(direction = 1) +
 labs(x = "Month", y = "Price", title = "Retail Price Across Months and Grouped by Stores", 
 subtitle = "In 2018") +
 theme_classic() 
)

```

</center>

> Looking at times series, we can see that not all stores have the same time trend, but most of them do.


### iv. How does price change with configuration?


<center>

```{r 82, echo=FALSE, warning=FALSE, comment=FALSE} 

#### Plot Of The Retail Price per Configuration
ggplotly(
ggplot(Retail_Price_Configuration) +
 aes(x = Configuration, y = Retail.Price) +
 geom_point(shape = "circle", size = 0.6) +
 scale_color_gradient() +
 labs(y = "Retail Price", title = "Retail Price and Configuration ", 
 subtitle = "In 2018") + geom_smooth() + theme_classic()
)
``` 

</center>

> Using an smooth approximator, we can see two differents trends, first a rapid increase in price while being at low configurations, and then the slope tend to stay constant and low, ending with a increase with highest configurations. 


## b.Location Questions


### i. Where are the stores and customers locatd?


```{r 9, echo=FALSE} 

#Transform UK to Worldwide Geodata

## For Client Data

Data_Client_Coordinates <- Laptop_Sales_Data[,.(customer.X,customer.Y)]
Data_Client_Coordinates <- na.omit(Data_Client_Coordinates)
Data_Client_Coordinates <- distinct(Data_Client_Coordinates)
Data_Client_Coordinates <- transform_coordinates(Data_Client_Coordinates,
                                                        latitude="customer.Y",longitude = "customer.X", from = projection_bng(), to = projection_wgs84())
Data_Client_Coordinates$customer.X <- as.numeric(Data_Client_Coordinates$customer.X)
Data_Client_Coordinates$customer.Y <- as.numeric(Data_Client_Coordinates$customer.Y)

## For Store Data

Data_Stores_Coordinates <- Laptop_Sales_Data[,.(store.X,store.Y)]
Data_Stores_Coordinates <- na.omit(Data_Stores_Coordinates)
Data_Stores_Coordinates <- distinct(Data_Stores_Coordinates)
Data_Stores_Coordinates <- transform_coordinates(Data_Stores_Coordinates,
                                                        latitude="store.Y",longitude = "store.X", from = projection_bng(), to = projection_wgs84())

Data_Stores_Coordinates$store.X <- as.numeric(Data_Stores_Coordinates$store.X)
Data_Stores_Coordinates$store.Y <- as.numeric(Data_Stores_Coordinates$store.Y)


```


```{r 84,echo=FALSE} 

#Ploting Map 

map_1 <- leaflet() %>% addProviderTiles(providers$CartoDB.Positron) %>% addMarkers(data=Data_Client_Coordinates, lng = ~Data_Client_Coordinates$customer.X, lat = ~Data_Client_Coordinates$customer.Y,icon = list(iconUrl='https://cdn-icons-png.flaticon.com/512/4573/4573516.png',iconSize=c(25,25)), clusterOptions = markerClusterOptions(),popup = ~paste("<h3>Client Coordinates</h3>","<b>Latitude:</b>",customer.X,"<b>Longitude:</b>",customer.Y)) %>% addMarkers(data=Data_Stores_Coordinates, lng = ~Data_Stores_Coordinates$store.X, lat = ~Data_Stores_Coordinates$store.Y,icon = list(iconUrl='https://cdn-icons-png.flaticon.com/512/726/726569.png',iconSize=c(25,25)), clusterOptions = markerClusterOptions(), popup = ~paste("<h3>Store Coordinates</h3>","<b>Latitude:</b>",store.X,"<b>Longitude:</b>",store.Y))

map_1

```


> Enjoy looking at each stores and customers in London UK ! You can find there exact location by clicking on them ! 

### ii. Which stores are selling the most?


```{r 10, include=FALSE}

Laptop_Sales_Data_2 <- Laptop_Sales_Data

Sales_Stores <- Laptop_Sales_Data_2[, .N, by=Store.Postcode]

Sales_Stores_2 <- Laptop_Sales_Data_2[,.(Revenues=sum(Retail.Price, na.rm = TRUE)),by=Store.Postcode]

```


<center>

```{r 103, echo=FALSE}

# Plot Transactions per Stores

ggplotly(
ggplot(Sales_Stores) +
 aes(x = reorder(Store.Postcode,-N), y = N) +
 geom_col(fill = "#1c6155") +
 labs(x = "Stores", 
 y = "Number Of Transactions", title = "Number of Transactions per Store", subtitle = "In 2018") +
 theme_classic() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
)

# Plot Revenues per Stores

ggplotly(
ggplot(Sales_Stores_2) +
 aes(x = reorder(Store.Postcode,-Revenues), y = Revenues) +
 geom_col(fill = "#1c6155") +
 labs(x = "Store Postcode", 
 y = "Revenues", title = "Revenues per Stores", subtitle = "In 2018") + 
 theme_classic()+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
)

```

</center>

> The following barplots show two ways of analyzing the stores sales results: by the number of transactions or the sales revenues they each generated during 2018.


### iii. How far would customers travel to buy a laptop ?


```{r 11}





```


### iv. How far would customers travel to buy a laptop ? - Alternative


```{r 111, include=FALSE}

# Distance Calculations

Distance_Customer_Shop_Data <- Laptop_Sales_Data[, .(customer.X,customer.Y,store.X,store.Y)]

Distance_Customer_Shop_Data <- distinct(Distance_Customer_Shop_Data)

Distance_Customer_Shop_Data <- na.omit(Distance_Customer_Shop_Data)

Distance_Customer_Shop_Data$customer.X <- as.numeric(Distance_Customer_Shop_Data$customer.X)
Distance_Customer_Shop_Data$customer.Y <- as.numeric(Distance_Customer_Shop_Data$customer.Y)
Distance_Customer_Shop_Data$store.X <- as.numeric(Distance_Customer_Shop_Data$store.X)
Distance_Customer_Shop_Data$store.Y <- as.numeric(Distance_Customer_Shop_Data$store.Y)

Distance_Customer <- transform_coordinates(Distance_Customer_Shop_Data, latitude="customer.Y",longitude = "customer.X", from = projection_bng(), to = projection_wgs84())

Distance_Customer <- Distance_Customer[,c(1,2)]

Distance_Store <- transform_coordinates(Distance_Customer_Shop_Data, latitude="store.Y",longitude = "store.X", from = projection_bng(), to = projection_wgs84())

Distance_Store <- Distance_Store[,c(3,4)]

All_Distance <- cbind(Distance_Customer,Distance_Store)

All_Distance <- All_Distance %>% rowwise() %>% mutate(Distance=distHaversine(c(customer.Y,customer.X),c(store.Y,store.X)))

```

```{r 1111,echo=FALSE}

datatable(All_Distance, colnames = c('Customer X ', 'Customer Y', 'Store X', 'Store Y', 'Distance Between Them in Meters'))

```


> Each Unique Customer can be found here, scroll down and see the distance they need to travel to get to their store.


## c.Revenue Questions


### i. How do the sales volume in each store relate to Acell's revenues?


```{r 12, include=FALSE}

Sales_Stores_Revenues <- Laptop_Sales_Data[,.(Revenues=sum(Retail.Price, na.rm = TRUE)), by= Store.Postcode]

Total_Revenue <- sum(Sales_Stores_Revenues$Revenues)

Sales_Stores_Revenues <- Sales_Stores_Revenues[,Percentage_Revenue:=Revenues/Total_Revenue]

Sales_Stores_Revenues$Percentage_Revenue <- Sales_Stores_Revenues$Percentage_Revenue*100

```


<center>

```{r 121,echo=FALSE}

ggplotly(
  ggplot(Sales_Stores_Revenues) +
 aes(x = reorder(Store.Postcode,-Percentage_Revenue), y = Percentage_Revenue) +
 geom_col(fill = "#1c6155") +
 labs(x = "Store Postcode", y = "% of Total Revenues", title = "Revenues Contribution per Stores", 
 subtitle = "In 2018") + 
 theme_classic()+theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
 )

```

</center>

> You can see the proportional revenues participation of each stores in 2018. 


### ii. How does this relationship depend on the configuration?


```{r 13}





```


## d.Configuration Questions 


### i. What are the details of each configuration? How does this relate to price?


```{r 14,include=FALSE}

Detail_Price <- Laptop_Sales_Data[,.(Retail.Price,Screen.Size..Inches.,Battery.Life..Hours.,RAM..GB.,Processor.Speeds..GHz.,HD.Size..GB.)]

Detail_Price <- na.omit(Detail_Price)

```


### ii. Do all stores sell all configurations?


```{r 15, include=FALSE}

Stores_Details <- Laptop_Sales_Data[,.(Store.Postcode,Configuration)]

Stores_Details <- na.omit(Stores_Details)

Stores_Details$Configuration <- as.integer(Stores_Details$Configuration)

```


<center>

```{r 151,echo=FALSE}

ggplotly(
ggplot(Stores_Details) +
 aes(x = Configuration) +
 geom_histogram(bins = 30L, fill = "#1c6155") +
 labs(x = "Stores ", 
 y = "Configurations Count", title = "Each Configurations per Stores", subtitle = "In 2018") +
 theme_classic() +
 facet_wrap(vars(Store.Postcode), scales = "free")
)

```

</center>

> With this multiple facets barplots, you can spot which configuration is less or not sold depending on the store.


# Ex 4.1

```{r a1, include=FALSE}

rm(list = ls()) # clean environment

```


